{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleGenomicNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPllEBkaDP3RqARBSBROGLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simecek/dspracticum2020/blob/master/lecture_08/assignment/e_coli_promoters/benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY8XHFTZg4X2"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQf-lv2qMxC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d582804-c41b-404a-e2b9-3b88895dcf0d"
      },
      "source": [
        "!pip install biopython"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 13.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from biopython) (1.18.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xTRv9r1JkcV"
      },
      "source": [
        "import urllib.request\n",
        "from pathlib import Path\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQDZyunCg8xk"
      },
      "source": [
        "## Reshaping data from fasta to txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuQYtHAVJ3wa"
      },
      "source": [
        "classes = ['nonpromoters', 'promoters']\n",
        "sets = ['train', 'valid']\n",
        "\n",
        "for c in classes:\n",
        "    for s in sets:\n",
        "        urllib.request.urlretrieve(f\"https://raw.githubusercontent.com/simecek/dspracticum2020/master/lecture_08/assignment/e_coli_promoters/e_coli_{c}_{s}.fa\", f\"e_coli_{c}_{s}.fa\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDYvcC64KBQo"
      },
      "source": [
        "for c in classes:\n",
        "    for s in sets:\n",
        "        Path(f\"data/{s}/{c}\").mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XVwjaUVKvnU"
      },
      "source": [
        "for c in classes:\n",
        "    for s in sets:\n",
        "        with open(f\"e_coli_{c}_{s}.fa\", \"r\") as fr:\n",
        "            for record in SeqIO.parse(fr, \"fasta\"):\n",
        "                id = record.id\n",
        "                with open(f\"data/{s}/{c}/{id}.txt\", \"w\") as fw:\n",
        "                    fw.writelines([\" \".join(str(record.seq))])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwWqL9UVhHRp"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QhJiddxQjnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5d9bb8-7179-4477-8b9a-e94d52cb96ca"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'data/train/',\n",
        "    batch_size=batch_size,\n",
        "    class_names=classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6791 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ15xyPEgIkd",
        "outputId": "8ef2ce10-da4c-4069-b5da-c4f2d7f3cfa6"
      },
      "source": [
        "raw_valid_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'data/valid/',\n",
        "    batch_size=batch_size,\n",
        "    class_names=classes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 750 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krNrCcl-Q2JH"
      },
      "source": [
        "vectorize_layer = TextVectorization(output_mode='int')\n",
        "\n",
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "vectorize_layer.set_vocabulary(vocab=np.asarray(['a', 'c', 't', 'g', 'n']))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlJsjlxlSJ8a"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text)-2, label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "valid_ds = raw_valid_ds.map(vectorize_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMEDEoL_h5RD"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5P0A9wVbQl2"
      },
      "source": [
        "# one-hot encoding\n",
        "onehot_layer = keras.layers.Lambda(lambda x: tf.one_hot(tf.cast(x,'int64'), 4))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWEUcqBXcecr"
      },
      "source": [
        "model_type = \"LSTM\"\n",
        "\n",
        "if model_type == \"LSTM\":\n",
        "    model = tf.keras.Sequential([\n",
        "          onehot_layer,\n",
        "          keras.layers.LSTM(128, return_sequences=True),\n",
        "          keras.layers.LSTM(128, return_sequences=False),\n",
        "          keras.layers.Dense(1, activation=\"sigmoid\")])                     \n",
        "else:\n",
        "    model = tf.keras.Sequential([\n",
        "        onehot_layer,\n",
        "        keras.layers.Conv1D(32, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(),\n",
        "        keras.layers.Conv1D(16, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(),\n",
        "        keras.layers.Conv1D(4, kernel_size=8, data_format='channels_last', activation='relu'),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        keras.layers.MaxPooling1D(),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.GlobalAveragePooling1D(),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\")])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J86X_OH-dUV2"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBIvfsEsddtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9ebf28-65de-4369-8183-936bff94b63b"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data = valid_ds)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5392 - accuracy: 0.7265 - val_loss: 0.4849 - val_accuracy: 0.7880\n",
            "Epoch 2/10\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.4761 - accuracy: 0.7862 - val_loss: 0.4316 - val_accuracy: 0.8027\n",
            "Epoch 3/10\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.4491 - accuracy: 0.7963 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.4139 - accuracy: 0.8201 - val_loss: 0.3931 - val_accuracy: 0.8200\n",
            "Epoch 5/10\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 0.4004 - accuracy: 0.8314 - val_loss: 0.3514 - val_accuracy: 0.8613\n",
            "Epoch 6/10\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.3937 - accuracy: 0.8284 - val_loss: 0.3756 - val_accuracy: 0.8400\n",
            "Epoch 7/10\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.3604 - accuracy: 0.8451 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.3472 - accuracy: 0.8555 - val_loss: 0.3253 - val_accuracy: 0.8560\n",
            "Epoch 9/10\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 0.3358 - accuracy: 0.8598 - val_loss: 0.3799 - val_accuracy: 0.8320\n",
            "Epoch 10/10\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 0.3371 - accuracy: 0.8620 - val_loss: 0.2961 - val_accuracy: 0.8760\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}