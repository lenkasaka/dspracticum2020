# Lecture 08

**Date**: Nov 23, 2020

**Slides**: https://docs.google.com/presentation/d/13bmhNEOAKByqNTih4YP-xk0oeLam51f97jrS4EcvitM/edit?usp=sharing

* Review
* Text classification
* BERT & Transformers
* Application of NLP methods on genomic data


## Examples (on the lesson)

* [Basic text classification](https://www.tensorflow.org/tutorials/keras/text_classification)
* [Text classification using TF Hub model](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub)
* [Simple classificatier of genomic sequences](https://github.com/simecek/dspracticum2020/blob/master/lecture_08/assignment/SimpleGenomicNN.ipynb)


## Videos

* [Transfer learning paradigm in NLP](https://www.youtube.com/watch?v=eKqWC577WlI)

## Additional materials

Hugging face (ðŸ¤—):

* [BERT](https://huggingface.co/bert-base-uncased)
* [Writing with transformers](https://transformer.huggingface.co/)
* [Hugging face colabs](https://huggingface.co/transformers/notebooks.html)

BERT & Transformers explained:

* [Attention is All You Need](https://arxiv.org/abs/1706.03762) paper: explained by a [blog post](https://mlexplained.com/2017/12/29/attention-is-all-you-need-explained/) and [video](https://www.youtube.com/watch?v=iDulhoQ2pro&ab_channel=YannicKilcher)
* [BERT paper](https://arxiv.org/abs/1810.04805): explained by a [blog post](https://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/) and [video](https://www.youtube.com/watch?v=OR0wfP2FD3c&ab_channel=HenryAILabs)

Language model for Czech & Czech sentiment classifier (my side project)

* [Czech-ULMFiT](https://github.com/simecek/Czech-ULMFiT) (PyTorch): [colab demo](https://colab.research.google.com/drive/1IAWBejZWvXDUirxA8RpBlV1sH3Mv8Uka?usp=sharing)

## Asignment 08

The goal was to train NN classifier over several classes of DNA sequences and beat a simple benchmark. More details [here](assignment/).